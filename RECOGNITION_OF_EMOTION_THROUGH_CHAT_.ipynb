{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucwcQcuU4DI1",
        "outputId": "deb2ed03-6303-41ed-f746-8ec5b41c44ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=7005c1d8010b33d4f75ed4e9d8bf1056d993b0b07818569a4138adfeebe7ce23\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "metadata": {
        "id": "ooKG7QCp4Kof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_time(s):\n",
        "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
        "    result = re.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "Xq_RoX-C31dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_author(s):\n",
        "    s = s.split(\":\")\n",
        "    if len(s)==2:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "VOjV8kWy4Q78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDatapoint(line):\n",
        "    splitline = line.split(' - ')\n",
        "    dateTime = splitline[0]\n",
        "    date, time = dateTime.split(\", \")\n",
        "    message = \" \".join(splitline[1:])\n",
        "    if find_author(message):\n",
        "        splitmessage = message.split(\": \")\n",
        "        author = splitmessage[0]\n",
        "        message = \" \".join(splitmessage[1:])\n",
        "    else:\n",
        "        author= None\n",
        "    return date, time, author, message"
      ],
      "metadata": {
        "id": "x3Vk3-g74Uto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "conversation = '/content/WhatsApp Chat with Aravindhan .txt'\n",
        "with open(conversation, encoding=\"utf-8\") as fp:\n",
        "    fp.readline()\n",
        "    messageBuffer = []\n",
        "    date, time, author = None, None, None\n",
        "    while True:\n",
        "        line = fp.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        if date_time(line):\n",
        "            if len(messageBuffer) > 0:\n",
        "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
        "            messageBuffer.clear()\n",
        "            date, time, author, message = getDatapoint(line)\n",
        "            messageBuffer.append(message)\n",
        "        else:\n",
        "            messageBuffer.append(line)"
      ],
      "metadata": {
        "id": "SnTX3Gz24btL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "Y544h2Ph5pLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.sentiment.vader"
      ],
      "metadata": {
        "id": "r_WGRu6q5348"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "PxAAjTZu6SFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxlVVU_f63Pu",
        "outputId": "e402ebf5-8cbc-4fe1-d1f2-bc19f1800184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.8/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vaderSentiment) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_pypuZ27TZw",
        "outputId": "3465f672-efb6-4992-ebfc-51521fece272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "data = df.dropna()\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()\n",
        "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"Message\"]]\n",
        "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"Message\"]]\n",
        "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"Message\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTZqIeef7VEZ",
        "outputId": "a5feebf0-e131-4c54-a81c-3e4a82d8704d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Date, Time, Author, Message, Positive, Negative, Neutral]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sum(data[\"Positive\"])\n",
        "y = sum(data[\"Negative\"])\n",
        "z = sum(data[\"Neutral\"])\n",
        "\n",
        "def sentiment_score(a, b, c):\n",
        "    if (a>b) and (a>c):\n",
        "        print(\"Positive ðŸ˜Š \")\n",
        "    elif (b>a) and (b>c):\n",
        "        print(\"Negative ðŸ˜  \")\n",
        "    else:\n",
        "        print(\"Neutral ðŸ™‚ \")\n",
        "sentiment_score(x, y, z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ7s4UGH7ach",
        "outputId": "1dd76d66-9a0a-4525-c038-f446e1481afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral ðŸ™‚ \n"
          ]
        }
      ]
    }
  ]
}